{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "sourceId": 6240823,
          "sourceType": "datasetVersion",
          "datasetId": 3585398
        },
        {
          "sourceId": 49128,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 41053,
          "modelId": 57522
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ma'lumot yo'llarini o'rnatish\n",
        "train_path = 'train'\n",
        "test_path = 'test'\n",
        "validation_path = 'validation'\n",
        "\n",
        "# Papka ichidagi rasmlar sonini aniqlash\n",
        "def count_images(data_path):\n",
        "    total_images = 0\n",
        "    for folder in range(33, 127):  # 33 dan 126 gacha\n",
        "        folder_path = os.path.join(data_path, str(folder))\n",
        "        if os.path.exists(folder_path):\n",
        "            image_files = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n",
        "            total_images += len(image_files)\n",
        "    return total_images\n",
        "\n",
        "# Train, test, validation papkalaridagi rasmlar sonini chop etish\n",
        "train_image_count = count_images(train_path)\n",
        "test_image_count = count_images(test_path)\n",
        "validation_image_count = count_images(validation_path)\n",
        "\n",
        "print(f\"Train papkasida {train_image_count} ta rasm bor.\")\n",
        "print(f\"Test papkasida {test_image_count} ta rasm bor.\")\n",
        "print(f\"Validation papkasida {validation_image_count} ta rasm bor.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMSVV_Hy_vy-",
        "outputId": "8baa2526-6eaf-4fe2-94c3-d43a5c91f89f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train papkasida 72609 ta rasm bor.\n",
            "Test papkasida 20719 ta rasm bor.\n",
            "Validation papkasida 10463 ta rasm bor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Ma'lumotlarni o'qish va tayyorlash\n",
        "def load_data(data_dir, csv_file):\n",
        "    # CSV faylni o'qish\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Rasmlarni o'qish\n",
        "    images = []\n",
        "    labels = []\n",
        "    valid_folders = [str(i) for i in range(33, 127) if i != 92] + ['999']\n",
        "    label_mapping = {folder: idx for idx, folder in enumerate(valid_folders)}\n",
        "\n",
        "    for folder in valid_folders:\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        if os.path.exists(folder_path):\n",
        "            for image_file in os.listdir(folder_path):\n",
        "                img = tf.keras.preprocessing.image.load_img(\n",
        "                    os.path.join(folder_path, image_file),\n",
        "                    color_mode='grayscale',\n",
        "                    target_size=(64, 64)\n",
        "                )\n",
        "                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "                images.append(img_array)\n",
        "                labels.append(label_mapping[folder])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Modelni yaratish\n",
        "def create_model(num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Asosiy qism\n",
        "def main():\n",
        "    # Ma'lumotlarni yuklash\n",
        "    train_images, train_labels = load_data('train/data', 'ascii_file_counts.csv')\n",
        "    val_images, val_labels = load_data('validation/data', 'ascii_file_counts.csv')\n",
        "\n",
        "    # Ma'lumotlarni normalizatsiya qilish\n",
        "    train_images = train_images / 255.0\n",
        "    val_images = val_images / 255.0\n",
        "\n",
        "    # Modelni yaratish\n",
        "    num_classes = 94  # 93 ta sinf (ASCII 33-126, 92 yo'q) + 1 (999 uchun)\n",
        "    model = create_model(num_classes)\n",
        "\n",
        "    # Modelni kompilatsiya qilish\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Modelni o'qitish\n",
        "    history = model.fit(train_images, train_labels, epochs=10,\n",
        "                        validation_data=(val_images, val_labels))\n",
        "\n",
        "    # Modelni saqlash\n",
        "    model.save('handwritten_text_recognition_model.h5')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKyKw5bEEb02",
        "outputId": "3315c761-82ea-4e1a-f9d8-aa8c4f5f26ec"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2379/2379 [==============================] - 50s 21ms/step - loss: 1.2408 - accuracy: 0.6644 - val_loss: 0.7309 - val_accuracy: 0.7742\n",
            "Epoch 2/10\n",
            "2379/2379 [==============================] - 51s 22ms/step - loss: 0.5971 - accuracy: 0.8098 - val_loss: 0.5946 - val_accuracy: 0.8081\n",
            "Epoch 3/10\n",
            "2379/2379 [==============================] - 50s 21ms/step - loss: 0.4868 - accuracy: 0.8404 - val_loss: 0.5096 - val_accuracy: 0.8363\n",
            "Epoch 4/10\n",
            "2379/2379 [==============================] - 48s 20ms/step - loss: 0.4171 - accuracy: 0.8582 - val_loss: 0.5110 - val_accuracy: 0.8349\n",
            "Epoch 5/10\n",
            "2379/2379 [==============================] - 49s 21ms/step - loss: 0.3665 - accuracy: 0.8736 - val_loss: 0.4847 - val_accuracy: 0.8437\n",
            "Epoch 6/10\n",
            "2379/2379 [==============================] - 50s 21ms/step - loss: 0.3226 - accuracy: 0.8869 - val_loss: 0.4897 - val_accuracy: 0.8423\n",
            "Epoch 7/10\n",
            "2379/2379 [==============================] - 49s 20ms/step - loss: 0.2869 - accuracy: 0.8966 - val_loss: 0.5061 - val_accuracy: 0.8411\n",
            "Epoch 8/10\n",
            "2379/2379 [==============================] - 49s 21ms/step - loss: 0.2576 - accuracy: 0.9063 - val_loss: 0.5041 - val_accuracy: 0.8468\n",
            "Epoch 9/10\n",
            "2379/2379 [==============================] - 48s 20ms/step - loss: 0.2311 - accuracy: 0.9149 - val_loss: 0.5285 - val_accuracy: 0.8426\n",
            "Epoch 10/10\n",
            "2379/2379 [==============================] - 49s 21ms/step - loss: 0.2086 - accuracy: 0.9226 - val_loss: 0.5660 - val_accuracy: 0.8427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def load_and_preprocess_image(image_path, target_size=(64, 64)):\n",
        "    # Load the image\n",
        "    img = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    # Normalize the image\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Add batch dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "def predict_image(model, image_path):\n",
        "    # Load and preprocess the image\n",
        "    processed_image = load_and_preprocess_image(image_path)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(processed_image)\n",
        "\n",
        "    # Get the predicted class\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "def map_class_to_character(predicted_class):\n",
        "    # Create a mapping from class index to ASCII value\n",
        "    valid_ascii = [i for i in range(33, 127) if i != 92] + [999]\n",
        "    class_to_ascii = {idx: ascii_val for idx, ascii_val in enumerate(valid_ascii)}\n",
        "\n",
        "    # Get the ASCII value for the predicted class\n",
        "    predicted_ascii = class_to_ascii[predicted_class]\n",
        "\n",
        "    # Convert ASCII to character (except for 999)\n",
        "    if predicted_ascii == 999:\n",
        "        return \"Unknown\"\n",
        "    else:\n",
        "        return chr(predicted_ascii)\n",
        "\n",
        "# Main prediction pipeline\n",
        "def predict_image_pipeline(model_path, image_path):\n",
        "    # Load the model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Predict the class\n",
        "    predicted_class = predict_image(model, image_path)\n",
        "\n",
        "    # Map the class to a character\n",
        "    predicted_character = map_class_to_character(predicted_class)\n",
        "\n",
        "    return predicted_character\n",
        "\n",
        "# Example usage\n",
        "model_path = 'handwritten_text_recognition_model.h5'\n",
        "image_path = '/content/test/100/10824.jpg'\n",
        "\n",
        "predicted_char = predict_image_pipeline(model_path, image_path)\n",
        "print(f\"The predicted character is: {predicted_char}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUunQkDiGk7W",
        "outputId": "d3fce414-7eeb-4c91-81a7-e2b5d9480c57"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n",
            "The predicted character is: d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lsyilNNdJb8z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}